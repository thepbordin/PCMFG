# =============================================================================
# PCFMG Environment Configuration Template
# =============================================================================
# Copy this file to .env and fill in your actual values.
# The .env file is git-ignored to protect your API keys.
# =============================================================================

# -----------------------------------------------------------------------------
# LLM API Configuration
# -----------------------------------------------------------------------------
# PCFMG requires an LLM API for emotion extraction. Choose one provider.
# Both OpenAI and Anthropic are supported.

# OpenAI API Configuration (recommended for GPT-4/GPT-4o)
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Anthropic API Configuration (recommended for Claude 3.5 Sonnet)
# Get your key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here

# -----------------------------------------------------------------------------
# Model Selection
# -----------------------------------------------------------------------------
# Specify which model to use. If not set, PCFMG will use the default for the
# configured API provider.

# OpenAI Models:
# - gpt-4o (recommended, best balance of speed/accuracy)
# - gpt-4-turbo-preview
# - gpt-3.5-turbo (faster, cheaper, less accurate)
LLM_MODEL=gpt-4o

# Anthropic Models:
# - claude-3-5-sonnet-20241022 (recommended)
# - claude-3-opus-20240229 (most accurate, slower)
# - claude-3-haiku-20240307 (fastest, cheapest)
# LLM_MODEL=claude-3-5-sonnet-20241022

# -----------------------------------------------------------------------------
# API Behavior Configuration
# -----------------------------------------------------------------------------

# Temperature parameter for LLM calls (0.0 to 1.0)
# Lower = more deterministic, Higher = more creative
# Default: 0.3
LLM_TEMPERATURE=0.3

# Maximum tokens for LLM responses
# Most emotion extraction tasks don't need more than 1000 tokens
# Default: 1000
LLM_MAX_TOKENS=1000

# Retry configuration for failed API calls
# Number of retry attempts (default: 3)
LLM_MAX_RETRIES=3

# -----------------------------------------------------------------------------
# Processing Configuration
# -----------------------------------------------------------------------------

# Beat detection strategy
# - automatic: Let LLM determine natural scene boundaries
# - length: Split text every N words
# - chapter: Split on chapter markers
BEAT_DETECTION=automatic

# Words per beat (only used when BEAT_DETECTION=length)
# Default: 500
BEAT_LENGTH=500

# Minimum beat length in words (prevents very short beats)
# Default: 200
MIN_BEAT_LENGTH=200

# Maximum beat length in words (prevents very long beats)
# Default: 1500
MAX_BEAT_LENGTH=1500

# -----------------------------------------------------------------------------
# Output Configuration
# -----------------------------------------------------------------------------

# Default output directory for analysis results
# Default: ./output
OUTPUT_DIR=./output

# Default output formats (comma-separated)
# Options: json, csv, png, pdf, markdown
# Default: json,png
OUTPUT_FORMATS=json,png

# DPI for generated plots (affects image quality and file size)
# Default: 300
PLOT_DPI=300

# Include statistical analysis report
# Options: true, false
# Default: true
INCLUDE_STATS=true

# -----------------------------------------------------------------------------
# Advanced Configuration
# -----------------------------------------------------------------------------

# Enable debug mode (verbose logging, intermediate outputs)
# Options: true, false
# Default: false
DEBUG=false

# Log level
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO
LOG_LEVEL=INFO

# Cache LLM responses (speeds up re-analysis, uses disk space)
# Options: true, false
# Default: true
CACHE_RESPONSES=true

# Cache directory
# Default: ./cache
CACHE_DIR=./cache

# Maximum concurrent API requests (for batch processing)
# Be careful not to exceed rate limits
# Default: 3
MAX_CONCURRENT_REQUESTS=3

# -----------------------------------------------------------------------------
# Text Processing Configuration
# -----------------------------------------------------------------------------

# Encoding for input text files
# Default: utf-8
TEXT_ENCODING=utf-8

# Ignore common header/footer text (e.g., Project Gutenberg headers)
# Options: true, false
# Default: true
IGNORE_BOILERPLATE=true

# Detect and skip non-narrative content (tables, indices, etc.)
# Options: true, false
# Default: true
SKIP_NON_NARRATIVE=true

# -----------------------------------------------------------------------------
# Example: Minimal Configuration
# -----------------------------------------------------------------------------
# For quick testing, you only need:
#
# OPENAI_API_KEY=sk-your-key-here
# LLM_MODEL=gpt-4o
#
# Or:
#
# ANTHROPIC_API_KEY=sk-ant-your-key-here
# LLM_MODEL=claude-3-5-sonnet-20241022

# -----------------------------------------------------------------------------
# Security Notes
# -----------------------------------------------------------------------------
# - NEVER commit your .env file to version control
# - Keep your API keys secret
# - Rotate keys if they're accidentally exposed
# - Consider using environment variables in production instead of .env
# - Check .gitignore includes .env
# -----------------------------------------------------------------------------
